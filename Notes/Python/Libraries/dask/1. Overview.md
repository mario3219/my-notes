Parallel computing library, good for handling tasks that inherently aren't bounded together in a sequential algorithm, but have properties that are connected and important for the end goal.

For example, finding global minima for a big library of images.

****
How dask handles processes that otherwise requires the computer to 'see' all data at once:

It gathers data in chunks, computes summaries in parallel and communicates between processes by shuffling data among each other and builds a merged structure.

It does not load the entire dataset, but it still handles all the data. It avoids RAM explosion by chunking and coordination, but still not skipping information.