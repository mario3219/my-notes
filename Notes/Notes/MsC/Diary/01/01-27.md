I keep reading about the GAT network today. So far, there shouldn't be a problem with directly incorporating into the I2C with foundation models.

I now have a rough grasp of the GAT network.

<u>Meeting</u>
Segmented versus unsegmented, isn't it better with unsegmented?
Overlapping tissue images and summarizing ROIs, won't it be an issue with overlapping cells?
Hard time finding more multiplex trained vision transformers, perhaps have transformer encode several images, to get all multiplex representations?
