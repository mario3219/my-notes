Started writing a skeleton code for downloading models and initiating them. I'm also adding arguments to the I2C code to call the models.

Markus proposed to just use the visual encoders in other foundation models, because they have pretrained visual encoders. So even though they are CNNs, it might be still viable

Skeleton code should be working, but i need to override/change load_state_dict functions.

I'm gonna try and extract the visual encoder in the DeepCell model.
I applied to deepcell.org to make an account, afterwards they will allow me to download the model.

Nothing to do now... except looking at the load state problem, or looking at other foundation models

Looking at Hibou-L model, trying to download it

I could download and instantiate the model, gonna check how i extract only the visual encoder

The model executes using build_model, which calls vision_transformer.py. I don't know how just calling it automatically builds everything, but here is where the visiontransformer is. The model is a nn.module, so i can easily remove the head to get the embeddings (perhaps it already is outputting embeddings?)

I need to figure out how the model is called, and how to load the weights for only that part.

Umm nevermind, i'm stupid, the foundation model itself is a vision transformer... the examples notebook shows how to use it