Today I will continue trying to get Image2Count to run.

So after my meeting with Markus, I got some things answered. The processed files are made during graph training, and the thing with data attribute missing in EmbedData due to skipping an if statement was a bug. So, after not referring to data attribute, the code works. 

Also, labels csv was in the wrong folder, supposed to be inside raw

Now I will continue making skeleton code for the foundation model.

Everything up until save_embed_data runs.

A bug? inside the function del self.data is used, but it was not initialized sometimes due to the if statement, might be the same bug as before.

Bugs out now because the tensor is 4 channels (as expected, the tiff images are 4 channels) but the model takes 3. One solution is to add a projection layer, but that needs training, and i cant be bothered writing a training algorithm.

I need to research more about how to fix this

Temporary solution is using the projection layer, and interpolating image sizes to the ViT model size.

****
<u>Embedding</u>
What happens:
* Datasets are created using EmbedDataset
* Model is initialized
* Model weights are loaded
* EmbedDataset save_embed_data is called using the model
* Inside save_embed_data, data is loaded from cells_path, which are the cells.npy files

What needs to be checked:
* (DONE) What type is data
	Answer: image tensor
* What type is embed.pt
* (DONE) Forward function for model
* (DONE) Overload the state_load function in GraphEmbed
	* Calls load, check what src.utils.utils.load does

****
(WORKS)
<u>src.utils.utils.load line 470</u>
Uses torch.load, with parameters:
* path
* map_location
* weights_only
torch.load is used to load objects saved when torch.save was used.
```model.load_state_dict(torch.load('model.pth'))```
Check if the same technique can be used with tiny

(CHECKED)
The ContrastiveLearning saves specific parts in the model using torch.save, have to check if this is important to follow

(WORKS)
The function gets called using:
`load(args['output_name'], save_keys='model', device=device)`
output_name is where the model is saved, so model creation has to take this argument and save model weights there

(WORKS)
src.utils.utils.load uses other arguments
`torch.load(path, map_location=device, weights_only=False)`
Check if these work

(WORK)
Tries to load 'model' from a dict loaded by torch.load.
The model when using torch.save, needs to have:
```
torch.save({
		"model": model.state_dict()
})
```