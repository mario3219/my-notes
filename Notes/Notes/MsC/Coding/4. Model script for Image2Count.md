Intended use:
* In cellcontrast.py, skip train_image_model argument, won't be used. Directly go to embed_image_data.
embed_image_data calls src.runCellContrastEmbed function embed.

* CellContrastEmbed has no arguments for which visual model to use, so an argument in cellcontrast.py needs to be added which handles which visual model to use

Added argument --foundation_model for cellcontrast.py, which is used in CellContrastEmbed to choose if the prior ResNet or foundation model Tiny is used for contrastive embedding

```
if args['foundation_model'] == 'TINY'
```

When calling the model in CellContrastEmbed, a valid input size needs to be passed.

The datasets embeds visual features by using their function save_embed_data inside their class src.data.CellContrastData EmbedDataset

****
<u>TODO</u>
* Change path strings to os for all scripts (or arguments)
**TinyModel.py**
* (DONE) Make sure model has attribute 'mode'
Because CellContrastEmbed.py calls model.mode
* (DONE) Add forward function
* (DONE) Look at .to(device) compatibiity, gets called in CellContrastData save_embed_data
* (DONE) Change download script to ViTForImageClassification in celldownload.py, and fix the load model in TinyModel.py
* load_state_dict gets called outside of the function, check that the way it is used works for TinyModel
* CellContrastEmbed uses src.utils.utils function load(), check if this returns the same as torch.load

**celldownload.py**
* (DONE) Change state save location

****

<u>Questions</u>
* Model is stored in local cache when it is first downloaded
~/.cache/torch/hub/
Will that be a problem for the server?