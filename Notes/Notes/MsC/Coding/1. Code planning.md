What needs to be done:
* Find the relative arguments from Image2Count, match it to input to foundation model, optimize output of foundation model to work with Image2Count
* Find out how to fine-tune the frozen parameters
* Find out how to just get Image2Count running
* Fix a repository of dummy images, using a .tiff file generator
* Find out how to store the model locally

**Workplan**

<u>For foundation model</u>
****
* (DONE) Find out how to store model locally
* (DONE) Find out how to use models
Was case dependent
* (SKIP) Find out how to fine tune model

<u>For Image2Count</u>
* Dummy single-layer visual feature model to replace ResNet in Image2C
Just to find out what arguments to take and output
* (DONE) Find out what steps are being performed for an image
i.e if its just straight into training and predicting

DataLoader from torch is used, which loads data automatically using test_set, which uses function EmbedDataSet in class CellContrastData in src.data.

EmbedDataSet seems to use the DataLoader as an interface, and enumerating the DataLoader returns index and batch. Batch is used as input for the model. The library when enumerated automatically calls some functions, that enumerates the dataset it is initiated with.

Is the reason for batches because of SGD? Is this when it is implemented?

When enumerating DataLoader, it calls getitem, and in the datasets, it is returning specific cell cutouts as tensors

Question: what is the tensors?
Line119 in CellContrastData, seems to load the cells to numpy, then to tensors, and stores them, the dataset doesnt get touched from there on
Conclusion: its image to tensor

* (DONE) Find out input type and output type of resnet model
Output type is a tensor, input is a tensor
Deit_tiny:
ImageClassifierOutput, BatchFeature

LUCKY! Tensors can be made into BatchFeature, so it can be directly converted into the I2C workflow

* Find out the input of the GAT
* Find out how the final GAT network leads to ROI prediction

<u>Other</u>
****
* (DONE )Dummy .tiff file generator
* (DONE) Fix conda environment
* csv generator

<u>Notes</u>
* Problem, the code is optimized for CNN's, so implementing a ViT model would require an overhaul of feature embeddings using ViT

<u>Questions</u>
* Dataloader, what are it's attributes? What does it produce? How are the inputs meant for the visual extractor formatted?
Answer: The visual inputs are of type tensor, but is it from image directly to tensor? My guess is yes, according to line 119 in CellContrastData script.

