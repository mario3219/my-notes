**Global, holistic interpretability**
Is about understanding how the model makes decisions based on a holistic view.
Holistic view means structural understanding, based on:
* Feature importance
* How the model reacts to various inputs
* What relationships the model has learned
* Where the model is stable, brittle or surprising

**Global interpretability on a modular level**
Understanding interpretable parts of the model, for example weights or splits

**Local interpretability for single prediction**
Understanding the process for a single prediction, which can give insight and linear behaviours

**Local interpretability for a group of predictions**
Understanding how the model handles a collective prediction
